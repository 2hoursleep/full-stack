# {{cookiecutter.project_name}}

## Back end local development

* Update your local `hosts` file, set the IP `127.0.0.1` (your `localhost`) to `{{cookiecutter.domain_dev}}`. The `docker-compose.override.yml` file will set the environment variable `SERVER_NAME` to that host. Otherwise you would receive 404 errors.

* Modify your hosts file, probably in `/etc/hosts` to include:

```
0.0.0.0    {{cookiecutter.domain_dev}}
```

...that will make your browser talk to your locally running server.

* Start the stack with Docker Compose:

```bash
docker-compose up -d
```

* Start an interactive session in the server container that is running an infinite loop doing nothing:

```bash
docker-compose exec backend bash
```

**Note**: Before the first run, make sure you create at least one "revision" of your models and database and make sure you create those models / tables in the database with `alembic`. See the section about migrations below for specific instructions.

* Run the local debugging Flask server, all the command is in the `RUN` environment variable:

```bash
$RUN
```

* Your OS will handle redirecting `{{cookiecutter.domain_dev}}` to your local stack. So, in your browser, go to: http://{{cookiecutter.domain_dev}}.

Add and modify SQLAlchemy models to `./backend/app/app/models/`, Marshmallow schemas to `./backend/app/app/schemas` and API endpoints to `./backend/app/app/api/`.

Add and modify tasks to the Celery worker in `./backend/app/app/worker.py`. 

If you need to install any additional package to the worker, add it to the file `./backend/app/Dockerfile-celery-worker`.

The `docker-compose.override.yml` file for local development has a host volume with your app files inside the container for rapid iteration. So you can update your code and it will be the same code (updated) inside the container. You just have to restart the server, but you don't need to rebuild the image to test a change. Make sure you use this only for local development. Your final production images should be built with the latest version of your code and do not depend on host volumes mounted.


### Back end tests

To test the back end run:

```bash
# Build the testing stack
docker-compose -f docker-compose.test.yml build
# Start the testing stack
docker-compose -f docker-compose.test.yml up -d
# Run the REST tests
docker-compose -f docker-compose.test.yml exec -T backend-rest-tests pytest
# Stop and eliminate the testing stack
docker-compose -f docker-compose.test.yml down -v
```

The tests run with Pytest, modify and add tests to `./backend/app/app/rest_tests/`.

If you need to install any additional package for the REST tests, add it to the file `./backend/app/Dockerfile-rest-tests`.

If you use GitLab CI the tests will run automatically.


### Migrations

As the `docker-compose.override.yml` file for local development mounts your app directory as a volume inside the container, you can also run the migrations with `alembic` commands inside the container and the migration code will be in your app directory (instead of being only inside the container). So you can add it to your git repository.

Make sure you create at least one "revision" of your models and that you "upgrade" your database with that revision at least once. As this is what will create the tables in your database. Otherwise, your application won't run.

* Start an interactive session in the server container that is running an infinite loop doing nothing:

```bash
docker-compose exec backend bash
```

* After changing a model (for example, adding a column) or when you are just starting, inside the container, create a revision, e.g.:

```bash
alembic revision --autogenerate -m "Add column last_name to User model"
```

* Commit to the git repository the files generated in the alembic directory.

* After creating the revision, run the migration in the database (this is what will actually change the database):

```bash
alembic upgrade head
```

If you don't want to use migrations at all, uncomment the line in the file at `./backend/app/app/core/database.py` with:

```python
Base.metadata.create_all(bind=engine)
```

## Front end development

* Enter the `frontend` directory, install the NPM packages and start it the `npm` scrits:

```bash
cd frontend
npm install
npm run start
```

Check the file `package.json` to see other available options.

## Deployment

To deploy the stack to a Docker Swarm run, e.g.:

```bash
docker stack deploy -c docker-compose.prod.yml --with-registry-auth {{cookiecutter.docker_swarm_stack_name_main}}
```

Using the corresponding Docker Compose file.

If you use GitLab CI, it will automatically deploy it. 

GitLab CI is configured assuming 3 environments following GitLab flow:

* `prod` (production) from the `production` branch.
* `stag` (staging) from the `master` branch.
* `branch`, from any other branch (a feature in development).


## URLs

These are the URLs that will be used and generated by the project.

### Production

Production URLs, from the branch `production`.

Front end: https://{{cookiecutter.domain_main}}

Back end: https://{{cookiecutter.domain_main}}/api/

Swagger UI: https://{{cookiecutter.domain_main}}/swagger/

PGAdmin: https://pgadmin.{{cookiecutter.domain_main}}

Flower: https://flower.{{cookiecutter.domain_main}}

### Staging

Staging URLs, from the branch `master`.

Front end: https://{{cookiecutter.domain_staging}}

Back end: https://{{cookiecutter.domain_staging}}/api/

Swagger UI: https://{{cookiecutter.domain_staging}}/swagger/

PGAdmin: https://pgadmin.{{cookiecutter.domain_staging}}

Flower: https://flower.{{cookiecutter.domain_staging}}

### Branch (feature branches)

Feature branch URLs, from any other branch.

Front end: https://{{cookiecutter.domain_branch}}

Back end: https://{{cookiecutter.domain_branch}}/api/

Swagger UI: https://{{cookiecutter.domain_branch}}/swagger/

PGAdmin: https://pgadmin.{{cookiecutter.domain_branch}}

Flower: https://flower.{{cookiecutter.domain_branch}}
    
### Development

Development URLs, for local development. Given that you modified your `hosts` file.

Front end: http://{{cookiecutter.domain_dev}}

Back end: http://{{cookiecutter.domain_dev}}/api/

Swagger UI: http://{{cookiecutter.domain_dev}}/swagger/

PGAdmin: http://{{cookiecutter.domain_dev}}:5050

Flower: http://{{cookiecutter.domain_dev}}:5555

Traefik UI: http://{{cookiecutter.domain_dev}}:8080

## Project Cookiecutter variables used during generation

* `project_name`: {{cookiecutter.project_name}}
* `project_slug`: {{cookiecutter.project_slug}}
* `domain_main`: {{cookiecutter.domain_main}}
* `domain_staging`: {{cookiecutter.domain_staging}}
* `domain_branch`: {{cookiecutter.domain_branch}}
* `domain_dev`: {{cookiecutter.domain_dev}}
* `docker_swarm_stack_name_main`: {{cookiecutter.docker_swarm_stack_name_main}}
* `docker_swarm_stack_name_staging`: {{cookiecutter.docker_swarm_stack_name_staging}}
* `docker_swarm_stack_name_branch`: {{cookiecutter.docker_swarm_stack_name_branch}}
* `secret_key`: {{cookiecutter.secret_key}}
* `first_superuser`: {{cookiecutter.first_superuser}}
* `first_superuser_password`: {{cookiecutter.first_superuser_password}}
* `postgres_password`: {{cookiecutter.postgres_password}}
* `pgadmin_default_user`: {{cookiecutter.pgadmin_default_user}}
* `pgadmin_default_user_password`: {{cookiecutter.pgadmin_default_user_password}}
* `traefik_constraint_tag`: {{cookiecutter.traefik_constraint_tag}}
* `traefik_constraint_tag_staging`: {{cookiecutter.traefik_constraint_tag_staging}}
* `traefik_constraint_tag_branch`: {{cookiecutter.traefik_constraint_tag_branch}}
* `traefik_public_network`: {{cookiecutter.traefik_public_network}}
* `traefik_public_constraint_tag`: {{cookiecutter.traefik_public_constraint_tag}}
* `flower_auth`: {{cookiecutter.flower_auth}}
* `sentry_dsn`: {{cookiecutter.sentry_dsn}}
* `docker_image_prefix`: {{cookiecutter.docker_image_prefix}}
* `docker_image_backend`: {{cookiecutter.docker_image_backend}}
* `docker_image_celeryworker`: {{cookiecutter.docker_image_celeryworker}}
* `docker_image_frontend`: {{cookiecutter.docker_image_frontend}}
